{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c328c34",
   "metadata": {},
   "source": [
    "# “Learning about Machine Learning with CRIM”\n",
    "\n",
    "\n",
    "**Abstract**\n",
    "\n",
    "In this tutorial-essay I will consider how we can use machine learning, speciﬁcally dimensionality reduction and embedding methods, with the CRIM corpus. The guiding question is how style can be modeled quantitatively. Building both on music-theoretical conceptualization and machine learning techniques, it will be demonstrated that unsupervised clustering can serve to some degree as a proxy for stylistic similarity. The CRIM data set provides an ideal case study that will also point to some shortcomings of the computational methodology that can only be resolved by a critical view, drawing on musicological expertise and close-reading of sources.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27077389-468d-4208-9215-a6749718f9e5",
   "metadata": {},
   "source": [
    "## Introduction: setting the scope"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56285e10",
   "metadata": {},
   "source": [
    "## Setup and obtaining the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43910965",
   "metadata": {},
   "source": [
    "We begin by installing the CRIM intervals library. \n",
    "\n",
    "```{bash}\n",
    "pip install --upgrade --force-reinstall git+https://github.com/HCDigitalScholarship/intervals.git@main \n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8164286c",
   "metadata": {},
   "source": [
    "Next we import all libraries and modules that we will need for our subsequent analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d3ada91-edd5-4b14-a1df-1449f188970d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import intervals as ci # crim intervals\n",
    "# import music21 as m21\n",
    "import pandas as pd # to work with tabular data\n",
    "\n",
    "import re # regular expressions\n",
    "import requests # to download files\n",
    "\n",
    "import os, glob # file I/O\n",
    "from tqdm import tqdm # status bar for loops\n",
    "\n",
    "import matplotlib.pyplot as plt # plots, plots, plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed18bf3c-590b-4d5b-8472-c5fe9a67842a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# us = m21.environment.UserSettings()\n",
    "# us.getSettingsPath()\n",
    "# us[\"musescoreDirectPNGPath\"] = \"/home/fmoss/.local/bin/mscore\"\n",
    "\n",
    "# import notebook\n",
    "# notebook.nbextensions.check_nbextension('usability/sphinx-markdown', user=True)\n",
    "\n",
    "# E = notebook.nbextensions.EnableNBExtensionApp()\n",
    "# E.toggle_nbextension('usability/sphinx-markdown/main')\n",
    "\n",
    "# c = m21.chord.Chord([\"C4\", \"E4\", \"G4\"])\n",
    "\n",
    "# hexa = ci.analysis.neoRiemannian.completeHexatonic(c, simplifyEnharmonics=True)\n",
    "# hexa\n",
    "\n",
    "# for chord in hexa:\n",
    "#     chord.duration=m21.duration.Duration(1.)\n",
    "\n",
    "# s = m21.stream.Stream(hexa)\n",
    "\n",
    "# s.show(\"text\")\n",
    "\n",
    "# s.show() # --> this doesn't work yet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d07466",
   "metadata": {},
   "source": [
    "We now access the CRIM corpus and download it to our working directory, so that we have to download it only once.\n",
    "First we get a list of the URLs pointing to each piece in the corpus following the instructions [here](https://github.com/RichardFreedman/CRIM_JHUB/blob/main/Make-me-a-Corpus.ipynb) and [here](https://github.com/RichardFreedman/CRIM_JHUB/blob/main/CRIM_04b_Cadences_Corpus.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb190e75-3339-4320-808f-d5ceaa625195",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_prefix = \"https://raw.githubusercontent.com/CRIM-Project/CRIM-online/master/crim/static/mei/MEI_4.0/\"\n",
    "URL = \"https://api.github.com/repos/CRIM-Project/CRIM-online/git/trees/990f5eb3ff1e9623711514d6609da4076257816c\"\n",
    "piece_json = requests.get(URL).json()\n",
    "piece_list = [raw_prefix + p[\"path\"] for p in piece_json[\"tree\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c748adc",
   "metadata": {},
   "source": [
    "The variable `piece_list` now contains all URLs and names of files in the CRIM corpus. We can inspect the first 5 items: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6508e477-bf8c-4300-acff-9346605abd9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://raw.githubusercontent.com/CRIM-Project/CRIM-online/master/crim/static/mei/MEI_4.0/CRIM_Mass_0001.mei',\n",
       " 'https://raw.githubusercontent.com/CRIM-Project/CRIM-online/master/crim/static/mei/MEI_4.0/CRIM_Mass_0001_1.mei',\n",
       " 'https://raw.githubusercontent.com/CRIM-Project/CRIM-online/master/crim/static/mei/MEI_4.0/CRIM_Mass_0001_2.mei',\n",
       " 'https://raw.githubusercontent.com/CRIM-Project/CRIM-online/master/crim/static/mei/MEI_4.0/CRIM_Mass_0001_3.mei',\n",
       " 'https://raw.githubusercontent.com/CRIM-Project/CRIM-online/master/crim/static/mei/MEI_4.0/CRIM_Mass_0001_4.mei']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "piece_list[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a39fb0",
   "metadata": {},
   "source": [
    "In total, we have `len(piece_list)` pieces: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcc9fc60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "307"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(piece_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbc71ae",
   "metadata": {},
   "source": [
    "There are 307 files in total. Downloading the files takes a certain amount of time. To speed this up, we save all files in `piece_list` in our local directory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53572d5c",
   "metadata": {},
   "source": [
    "First, we create a new directory `data/` but only if it does not already exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d108d8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = \"data/\"\n",
    "if not os.path.exists(d):\n",
    "    os.makedirs(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a293512d",
   "metadata": {},
   "source": [
    "Next, we iterate over `piece_list`, request the file from the server and save it to that directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1c2904b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 307/307 [00:00<00:00, 2543.47it/s]\n"
     ]
    }
   ],
   "source": [
    "for piece in tqdm(piece_list):\n",
    "    filename = piece.split(\"/\")[-1] # only the part after the last '/' is the filename    \n",
    "    with open(d + filename, 'wb') as f:\n",
    "        if not os.path.exists(d + filename):\n",
    "            r = requests.get(piece)\n",
    "            f.write(r.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab67285",
   "metadata": {},
   "source": [
    "We create a new list `local_files` containing all local file paths and names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "190eeb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_files = glob.glob(\"data/*.mei\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0326429",
   "metadata": {},
   "source": [
    "So now we have a list of file names pointing to MEI files in our local `data/` directory. At a closer look you'll see that some of them end in something like `0001_1.mei` but a few others end in `0001.mei`. There is a pattern to this. The files without the trailing digit are 'wrappers' that bind all movements (indexed 1 through 9) of a particular mass (indexed 0001 through 9999) together. Since these wrappers do not contain any notes or cadences (those are stored in the MEI files of the respective movements), we'll filter them out. \n",
    "\n",
    "Fortunately, this is very easy since the filenames are chosen systematically. We only need to remove all files from the `local_files` list that have a file name ending in `_d.mei`, where `d` stands for any integer from 1 to 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c51a402",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_files = [ f  for f in local_files if re.match(r\".+_\\d.mei$\", f) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68eed739",
   "metadata": {},
   "source": [
    "What happened here? We defined a pattern according to which we were able to remove the wrapper file names. This pattern is here expressed as a **regular expression**: `r\".+_\\d.mei$\"`\n",
    "\n",
    "Let's take it apart to understand how it works.\n",
    "As you probably now, strings in Python are surrounded by either one or two quotation marks (`'` or `\"`). The `r` prefixed to the expression tells the interpreter that the string enclosed in quotes is a regular expression and that the characters have to be interpreted accordingly. \n",
    "\n",
    "Next, we see a period `.`. This symbol stands for \"any character\" in a regular expression. The following `+` means \"one or more\", so that the combination `.+` stands for a sequence of any characters of length at least 1. With this, we capture the part of the filename preceding the underscore `_`. \n",
    "\n",
    "Since the pattern differs towards the end of the file names, we can also view it from the end: The `$` sign marks the end of the string, so that everything to its left has to come just before. Since we are dealing with MEI files, each file name ends with `.mei`, which is exactly what we see before the `$`. \n",
    "\n",
    "Now the crucial part. The 'wrapper' files do not have an underscore followed by a single-digit integer. We can use this information and represent that integer with `\\d`. \n",
    "\n",
    "Consequently, filenames **not** following this pattern (not being captured by the regular expression) will not be taken into account. In English, we could read the list comprehension for `local_files` as: \"make a list of filenames where each filename conforms to the pattern defined by the regular expression\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d3e0c268",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "220"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(local_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea8afb0",
   "metadata": {},
   "source": [
    "Apparently, there are \"only\" 220 individual mass movements. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97bca395",
   "metadata": {},
   "source": [
    "## Transforming the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981bb738",
   "metadata": {},
   "source": [
    "Now that we have all files nicely stored in our local directory, it is finally time to access them. The CRIM intervals library (imported as `ci`, see above) provides a convenient way to do so: we create a `corpus` by passing a list of files to the `CorpusBase` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "29d97f84-8d54-4962-9a38-32d962ec4989",
   "metadata": {},
   "outputs": [
    {
     "ename": "ParseError",
     "evalue": "no element found: line 1, column 0 (<string>)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  File \u001b[1;32m~/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3378\u001b[0m in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
      "\u001b[0m  Cell \u001b[1;32mIn [15], line 1\u001b[0m\n    corpus = ci.CorpusBase(local_files)\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m~/.local/lib/python3.10/site-packages/intervals/main_objs.py:2419\u001b[0m in \u001b[1;35m__init__\u001b[0m\n    _score = importScore(path)\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m~/.local/lib/python3.10/site-packages/intervals/main_objs.py:48\u001b[0m in \u001b[1;35mimportScore\u001b[0m\n    mei_doc = ET.fromstring(to_import)\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m~/miniconda3/envs/crim/lib/python3.10/xml/etree/ElementTree.py:1343\u001b[0;36m in \u001b[0;35mXML\u001b[0;36m\n\u001b[0;31m    return parser.close()\u001b[0;36m\n",
      "\u001b[0;36m  File \u001b[0;32m<string>\u001b[0;36m\u001b[0m\n\u001b[0;31mParseError\u001b[0m\u001b[0;31m:\u001b[0m no element found: line 1, column 0\n"
     ]
    }
   ],
   "source": [
    "corpus = ci.CorpusBase(local_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1225fe96-16d4-4bc1-af17-022c89bceea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus.batch(func=ci.ImportedPiece.ngrams)[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c7c976",
   "metadata": {},
   "source": [
    "## The vector-space model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ec0765",
   "metadata": {},
   "source": [
    "### $n$-grams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb29c8f",
   "metadata": {},
   "source": [
    "### Term frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c592f2b9",
   "metadata": {},
   "source": [
    "### Document frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edcf789d",
   "metadata": {},
   "source": [
    "### Term frequency - inverse document frequency (TF-IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026e1226",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_all(df, normalize=False):\n",
    "    s = pd.concat([df[col] for col in df.columns])\n",
    "    return s.value_counts(normalize=normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51934ea-2879-4510-a2ec-adc43a56e156",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_all(corpus.scores[2].getNoteRest(), normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70854427-c0c6-4c8c-b949-8a9e71b48bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = pd.DataFrame([ count_all( corpus.scores[i].getNoteRest()) for i in range(len(corpus.scores)) ]).reset_index(drop=True)\n",
    "counts = counts.fillna(1)# fill NaN values\n",
    "del counts[\"Rest\"]\n",
    "counts = counts.iloc[:,:20]\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b8b4a2-59f9-4827-b7f4-197bb4ecfa10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "dia = [\"B-\"] + list(\"FCGDAEB\") + [\"Rest\"]\n",
    "\n",
    "cmap = plt.get_cmap('tab20')\n",
    "colors = cmap(np.linspace(0, 1, len(dia)))\n",
    "\n",
    "c = [colors[dia.index(l)] for l in counts.idxmax(axis=1).apply(lambda x: x[:-1] if x[-1] != \"t\" else x).values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d642747d-c387-400e-9662-c33f0408ddf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = counts.div(counts.sum(axis=1), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8baa47d1-4546-424f-9289-f8baeede323e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = counts.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460c7a85-9fcf-46c2-9833-95743113ac26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d100a94a-d4eb-4b4c-a494-b1119d183f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c3a4b7-4eb0-46df-a0d6-c28ff9b0ec6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5dfe32-957a-4f0f-b03f-54ab52e39813",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_[:,0], X_[:,1], alpha=.75, zorder=3, c=c)\n",
    "plt.axhline(0, lw=.5, c=\"k\")\n",
    "plt.axvline(0, lw=.5, c=\"k\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09e4e82-1b01-490a-b4a5-10fb54cac1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee32d272-e330-46ea-938a-a2fec6ee8511",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2, metric=\"cosine\", perplexity=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c41c13-493f-4ef4-89af-911b195d0f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "X__ = tsne.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c90da96-addc-4e14-9598-5f65d6d950f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X__[:,0], X__[:,1], alpha=.75, zorder=3, c=c)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a4c4d1-ad1b-48b9-a5fc-7067c7e43064",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55bb3db-8c73-456e-8505-34e37e61dc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus.scores[3].analyses[\"note_list\"][4].note"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a2c203",
   "metadata": {},
   "source": [
    "## Dimensionality reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3274464a",
   "metadata": {},
   "source": [
    "### The idea"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64115662",
   "metadata": {},
   "source": [
    "### Principal Components Analysis (PCA): a simple and popular method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721b0188",
   "metadata": {},
   "source": [
    "### Uniform Manifold Approximation & Projection (UMAP): a complex and popular method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6010a27c",
   "metadata": {},
   "source": [
    "## On style"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2fbb44c",
   "metadata": {},
   "source": [
    "Meyer quote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc07ea2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "0959e50e071deeafc5c01a8be4f9501c51325c41ddbb3c97d48d41d7ccdfbb0b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
